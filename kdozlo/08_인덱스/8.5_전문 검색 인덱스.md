# 8.5 전문 검색 인덱스
- 문서의 전체 텍스트를  
    1. 토큰 단위로 분해(tokenization)  
    2. 불용어(“그리고”, “그는” 등 의미가 약하고 자주 등장하는 단어)의 제거  
    3. 어간 추출(stemming) 또는 형태소 분석 등을 통해 정규화(normalization)  
    4. 각 토큰(token)이 등장한 문서의 ID 목록을 역색인(inverted index) 형태로 저장  
- 사용자가 검색 키워드를 입력하면, 해당 키워드를 포함하고 있는 문서들의 ID를 인덱스에서 즉시 찾아내어 전체 문서를 일일이 훑어보지 않고도 결과를 반환할 수 있도록 도움

## 8.5.1 인덱스 알고리즘

### 키워드 인덱싱 기법
- 어근 분석 알고리즘
- n-gram 분석 알고리즘

### 8.5.1.1 어근 분석 알고리즘
- 불용어 처리, 어근 분석 과정을 거쳐서 색인 작업 수행
- 불용어 처리
    - 검색에서 가치 없는 단얼르 필터링하여 제거하는 작업
    - 불용어는 코드에 상수로 정의해서 사용 -> 불용어 개수가 많지 않기 때문
    - 또는, 불용어 자체를 데이터베이스화 해서 사용 -> 사용자가 추가하거나 삭제 가능
- 어근 분석
    - 검색어로 선정된 단어의 뿌리인 원형을 찾는 작업
    - MeCab
        - 오픈소스 라이브러리를 플러그인 형태로 MySQL에서 사용 가능
        - 형태소 분석 -> 명사와 조사 구분
        - 단어 사전, 문장 구조 인식(단어 품사 식별) 필요
        - 전문 검색 알고리즘이기 때문에 많은 노력과 시간 필요
    - 국가 언어별로 어근이나 형태소 분석 방식이 다름 -> 맞는 라이브러리 사용 하기

### 8.5.1.2 n-gram 알고리즘
- 키워드 검색을 위한 인덱싱 알고리즘
- 본문을 무조건 몇 글자씩 잘라서 인덱싱하는 방법
- 형태소 분석보다 단순, 국가별 언어별 이해와 준비 작업 필요 X
- 만들어진 인덱스의 크기 상당히 큰 편
- n: 인덱싱할 키워드의 최소 글자 수
- e.g. 2-gram(Bi-gram) 방식 많이 사용

### 2-gram 알고리즘
- `To be or not to be. That is the question`문장에 2-gram 알고리즘 적용
- 공백과 마침표를 기준으로 구분 -> 2글자씩 중첩해서 토큰으로 분리
    - `To, be, or, no,ot, to, be, Th,ha,at, is, th,he, qu,ue,es,st,ti,io,on`
- 생성된 토큰들중 불용어 일치나 포함 걸러내기 수행
    - `at, be, ha, io, is, on, or, ti, To, to` 걸러짐
    - `SELECT * FROM information_schema.INNODB_FT_DEFAULT_STOPWORD`를 통해 MySQL에 내장된 불용어 확인 가능
- `es, he, no, ot, qu, st, Th, th, ue` 전문 검색 인덱스에 등록된다.

### 8.5.1.3 불용어 변경 및 삭제
- `ti, at, ha` 토큰의 경우 `a, i`철자가 불용어로 등록돼 있어 걸러짐
    - 이런 불용어 처리 방식은 사용자에게 도움 안됨
    - 불용어 처리 무시나 불용어 사용자화 방법 쓰기

### 전문 검색 인덱스의 불용어 처리 무시
1. MySQL 서버의 모든 전문 검색 인덱스에 대해 불용어를 완전히 제거
    - MySQL 설정 파일(my.cnf)의 `ft_stopword_file` 시스템 변수에 빈 문자열 설정 -> MySQL 서버 재시작
2. InnoDB를 사용하는 테이블의 전문 검색 인덱스에서만 불용어 처리 무시
    - `innodb_ft_enable_stopword` OFF 설정하기(MySQL 서버 실행 중인 상태에서도 변경 가능)

### 사용자 정의 불용어 사용
1. 불용어 목록 파일화 -> `ft_stopword_file`에 파일 경로 등록
2. 불용어 목록을 테이블로 저장
    - InnoDB를 사용하는 테이블의 전문 검색 엔진에서만 사용 가능
    - 불용어 테이블 생성 -> `innodb_ft_server_stopword_table`에 불용어 테이블 설정
    - 불용어 목록 변경 후, 전문 검색 인덱스 생성돼어야 변경된 불용어 적용됨
    ```sql
    -- 불용어 테이블 생성
    CREATE TABLE my_stopword(value VARCHAR(30)) ENGINE = INNODB;

    -- 원하는 단어 삽입

    -- 변수 설정
    SET GLOBAL innodb_ft_server_stopword_table='mydb/my_stopword';

    -- 전문 검색 인덱스 생성
    ALTER TABLE tb_bi_gram
        ADD FULLTEXT INDEX fx_title_body(title, body) WITH PARSER ngram;
    ```

## 8.5.2 전문 검색 인덱스의 가용성
- 전문 검색 인덱스 사용을 위한 조건
    1. 쿼리 문장이 전문 검색을 위한 문법(MATCH ... AGAINST ...)을 사용
    2. 테이블이 전문 검색 대상 칼럼에 대해서 전문 인덱스 보유
- 예시
    ```sql
    CREATE TABLE tb_test (
        doc_id INT,
        doc_body TEXT,
        PRIMARY KEY (doc_id),
        FULLTEXT KEY fx_docbody (doc_body) WITH PARSER ngram
    ) ENGINE=InnoDB

    -- 전문 검색 인덱스 이용X, 풀 테이블 스캔
    SELECT * FROM tb_test WHERE doc_body LIKE '%애플%';

    -- 전문 검색 인덱스 사용
    SELECT * FROM tb_test
        WHERE MATCH(doc_body) AGAINST('애플' IN BOOLEAN MODE);
    ```
